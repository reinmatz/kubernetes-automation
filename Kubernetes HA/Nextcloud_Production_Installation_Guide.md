# Nextcloud Production Installation auf Kubernetes - Kompletter Leitfaden

## Inhaltsverzeichnis

1. [EinfÃ¼hrung](#1-einfÃ¼hrung)
2. [Voraussetzungen](#2-voraussetzungen)
3. [Architektur-Ãœbersicht](#3-architektur-Ã¼bersicht)
4. [Stufe 1: Basis-Installation](#4-stufe-1-basis-installation)
5. [Stufe 2: Production-Ready Features](#5-stufe-2-production-ready-features)
6. [Stufe 3: Monitoring & HA-Integration](#6-stufe-3-monitoring--ha-integration)
7. [Backup & Restore](#7-backup--restore)
8. [Troubleshooting](#8-troubleshooting)
9. [Wartung & Updates](#9-wartung--updates)
10. [Best Practices](#10-best-practices)

---

## 1. EinfÃ¼hrung

### Was ist dieses Projekt?

Dieses Dokument fÃ¼hrt Sie Schritt fÃ¼r Schritt durch die Installation einer **produktionsreifen Nextcloud-Instanz** auf Kubernetes. Nextcloud ist eine Open-Source-Plattform fÃ¼r Cloud-Speicher, Dateifreigabe und Kollaboration - Ã¤hnlich wie Dropbox oder Google Drive, aber selbst gehostet.

### Warum Kubernetes fÃ¼r Nextcloud?

- âœ… **HochverfÃ¼gbarkeit**: Keine Downtime bei Server-AusfÃ¤llen
- âœ… **Skalierbarkeit**: Automatische Anpassung an Last
- âœ… **Automatisierung**: Self-Healing, automatische Backups
- âœ… **Isolation**: Saubere Trennung von anderen Anwendungen

### Progressive Lern-Struktur

Dieses Dokument ist in **3 Stufen** aufgebaut:

1. **Stufe 1 - Basis**: Funktionierende Nextcloud + MariaDB (Lernfokus)
2. **Stufe 2 - Production**: HochverfÃ¼gbarkeit, Security, Resource Management
3. **Stufe 3 - Enterprise**: Monitoring, Backup, Integration mit HA-Cluster

Jede Stufe baut auf der vorherigen auf. Sie kÃ¶nnen bei Stufe 1 stoppen (fÃ¼r Testsysteme) oder alle Stufen durchlaufen (fÃ¼r Produktionssysteme).

---

## 2. Voraussetzungen

### Was Sie brauchen

#### Kubernetes-Cluster
- Funktionierende Kubernetes-Installation (v1.24+)
- Zugriff via `kubectl` konfiguriert
- StorageClass fÃ¼r persistente Volumes verfÃ¼gbar

```bash
# Cluster-Status prÃ¼fen
kubectl cluster-info
kubectl get nodes

# StorageClass prÃ¼fen (mindestens eine sollte verfÃ¼gbar sein)
kubectl get storageclasses
```

**Erwartetes Ergebnis:**
```
NAME                 PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE
local-path (default) rancher.io/local-path   Delete          WaitForFirstConsumer
```

#### Software-Voraussetzungen
- `kubectl` (v1.24+) installiert
- `openssl` fÃ¼r Passwort-Generierung
- Optional: `oc` (OpenShift CLI) fÃ¼r erweiterte Funktionen
- Optional: `helm` (v3) fÃ¼r Helm-Charts

```bash
# Versionen prÃ¼fen
kubectl version --client
openssl version
```

#### Netzwerk-Anforderungen (je nach Stufe)

**Stufe 1 (Basis):**
- Port-Forwarding fÃ¼r lokalen Zugriff ausreichend

**Stufe 2 (Production):**
- Ingress Controller installiert (z.B. Nginx Ingress)
- DNS-Eintrag oder `/etc/hosts` Eintrag

**Stufe 3 (Enterprise):**
- MetalLB oder externer Load Balancer
- Cert-Manager fÃ¼r TLS-Zertifikate
- Prometheus Operator fÃ¼r Monitoring

### Ressourcen-Planung

#### Minimum-Anforderungen (Stufe 1 - Test/Dev)
```
MariaDB:
  CPU: 500m
  Memory: 512Mi
  Storage: 5Gi

Nextcloud:
  CPU: 500m
  Memory: 512Mi
  Storage: 5Gi
```

#### Empfohlene Anforderungen (Stufe 2+3 - Production)
```
MariaDB (StatefulSet):
  CPU: 1000m
  Memory: 2Gi
  Storage: 20Gi

Nextcloud (3 Replicas):
  CPU: 1000m (pro Pod)
  Memory: 1Gi (pro Pod)
  Storage: 50Gi (shared)
```

---

## 3. Architektur-Ãœbersicht

### Gesamtarchitektur (alle Stufen)

```
                    Internet / Lokales Netzwerk
                               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              Stufe 3: Ingress (TLS)              â”‚
    â”‚         nextcloud.yourdomain.com (HTTPS)         â”‚
    â”‚                  Cert-Manager                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Stufe 2: Load Balancer Service           â”‚
    â”‚              (MetalLB: externe IP)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Nextcloud   â”‚            â”‚  Nextcloud   â”‚
    â”‚   Pod 1      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Pod 2      â”‚
    â”‚              â”‚  Session   â”‚              â”‚
    â”‚ Replica 1/3  â”‚  Sharing   â”‚ Replica 2/3  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
         â””â”€â”€â”€â”€â”€â–ºâ”‚ Nextcloud    â”‚â—„â”€â”€â”€â”€â”€â”€â”˜
                â”‚   Pod 3      â”‚
                â”‚ Replica 3/3  â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Service: nextcloud-svc    â”‚
         â”‚      (ClusterIP/LB)         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PVC: nextcloud-data (RWX)  â”‚
         â”‚      50Gi - Shared Storage  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                       â”‚
                       â”‚ Database Connection
                       â”‚ (mysql://mariadb:3306)
                       â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Service: mariadb          â”‚
         â”‚      ClusterIP: 3306        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   StatefulSet: mariadb       â”‚
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚   â”‚  mariadb-0         â”‚     â”‚
         â”‚   â”‚  (Primary)         â”‚     â”‚
         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚            â”‚                 â”‚
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚   â”‚ PVC: mariadb-data  â”‚     â”‚
         â”‚   â”‚   (RWO - 20Gi)     â”‚     â”‚
         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Secret: nextcloud-db     â”‚
         â”‚  - DB_PASSWORD              â”‚
         â”‚  - DB_USER                  â”‚
         â”‚  - DB_NAME                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stufe 3: Monitoring Stack   â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚ â”‚ Prometheus              â”‚ â”‚
         â”‚ â”‚  - ServiceMonitor       â”‚ â”‚
         â”‚ â”‚  - Metrics Scraping     â”‚ â”‚
         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚ â”‚ Grafana                 â”‚ â”‚
         â”‚ â”‚  - Nextcloud Dashboard  â”‚ â”‚
         â”‚ â”‚  - MariaDB Metrics      â”‚ â”‚
         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stufe 3: Backup Strategy    â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚ â”‚ CronJob: db-backup      â”‚ â”‚
         â”‚ â”‚  Schedule: Daily 2 AM   â”‚ â”‚
         â”‚ â”‚  Retention: 7 days      â”‚ â”‚
         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
         â”‚ â”‚ PVC Snapshots           â”‚ â”‚
         â”‚ â”‚  (VolumeSnapshot)       â”‚ â”‚
         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponenten-Ãœbersicht

| Komponente | Typ | Zweck | Stufe |
|------------|-----|-------|-------|
| **nextcloud** | Deployment (spÃ¤ter: 3 Replicas) | Nextcloud-Anwendung | 1, 2 |
| **mariadb** | StatefulSet | Datenbank (persistent identity) | 1, 2 |
| **nextcloud-svc** | Service (ClusterIP â†’ LoadBalancer) | Interner/Externer Zugriff | 1, 2, 3 |
| **mariadb-svc** | Service (ClusterIP) | DB-Zugriff fÃ¼r Nextcloud | 1 |
| **nextcloud-data** | PVC (ReadWriteMany) | Nextcloud-Dateien (geteilt) | 1, 2 |
| **mariadb-data** | PVC (ReadWriteOnce) | Datenbank-Daten | 1, 2 |
| **nextcloud-db** | Secret | Datenbank-Credentials | 1 |
| **nextcloud-ingress** | Ingress | HTTPS-Zugriff mit Domain | 3 |
| **certificate** | Certificate (Cert-Manager) | TLS-Zertifikat | 3 |
| **nextcloud-monitor** | ServiceMonitor | Prometheus-Integration | 3 |
| **db-backup** | CronJob | Automatische Backups | 3 |
| **network-policies** | NetworkPolicy | Pod-zu-Pod-Isolation | 2 |

---

## 4. Stufe 1: Basis-Installation

### Ãœbersicht Stufe 1

In dieser Stufe erstellen wir eine **funktionierende Nextcloud-Installation** mit:
- âœ… Nextcloud-Pod (1 Replica)
- âœ… MariaDB-Pod (Single Instance)
- âœ… Persistenter Storage fÃ¼r beide
- âœ… Grundlegende Konfiguration
- âœ… Zugriff via Port-Forwarding

**Zeitaufwand:** ~15-20 Minuten
**Ziel:** Verstehen der Kubernetes-Grundlagen und funktionierende Nextcloud

---

### 4.1 Namespace erstellen

#### Was ist ein Namespace?

Ein Namespace ist wie ein **virtueller Cluster** innerhalb Ihres Kubernetes-Clusters. Er isoliert Ressourcen voneinander und ermÃ¶glicht:
- Logische Trennung (z.B. dev/test/prod)
- Resource Quotas pro Namespace
- Bessere Ãœbersichtlichkeit

#### Schritt-fÃ¼r-Schritt

```bash
# 1. Namespace erstellen
kubectl create namespace nextcloud-prod

# 2. Namespace verifizieren
kubectl get namespaces

# 3. Namespace als Standard setzen (optional, aber empfohlen)
kubectl config set-context --current --namespace=nextcloud-prod

# 4. Aktuellen Context prÃ¼fen
kubectl config get-contexts
```

**Erwartetes Ergebnis:**
```
NAME                READY   STATUS    AGE
nextcloud-prod      Active            5s
```

**Was passiert hier?**
- Kubernetes erstellt einen neuen Namespace
- Alle folgenden Ressourcen werden in diesem Namespace erstellt
- Isolation von anderen Projekten/Anwendungen

---

### 4.2 Secrets fÃ¼r Datenbank-Credentials erstellen

#### Was sind Secrets?

Secrets speichern **sensible Daten** (PasswÃ¶rter, API-Keys, Zertifikate) sicher in Kubernetes. Sie sind:
- Base64-kodiert (nicht verschlÃ¼sselt!)
- Separat von Anwendungs-Code gespeichert
- KÃ¶nnen als Environment-Variablen oder Dateien eingebunden werden

#### Warum Secrets statt Klartext?

âŒ **FALSCH** (Passwort im Deployment):
```yaml
env:
- name: MYSQL_ROOT_PASSWORD
  value: "MyPassword123"  # â† Nie so machen!
```

âœ… **RICHTIG** (Passwort in Secret):
```yaml
env:
- name: MYSQL_ROOT_PASSWORD
  valueFrom:
    secretKeyRef:
      name: nextcloud-db
      key: MYSQL_ROOT_PASSWORD
```

#### Schritt-fÃ¼r-Schritt: PasswÃ¶rter generieren und Secret erstellen

```bash
# 1. Starkes Passwort generieren (Linux/macOS)
# Option A: Ãœber Terminal-Eingabe (sicherer, kein History-Eintrag)
read -s -p 'Datenbankpasswort: ' DB_PASSWORD
echo

# Option B: Automatisch generieren
DB_PASSWORD=$(openssl rand -base64 32)
echo "Generiertes Passwort: $DB_PASSWORD"
# âš ï¸ WICHTIG: Passwort sicher speichern (z.B. in Password Manager)!

# 2. Secret mit allen benÃ¶tigten Variablen erstellen
kubectl create secret generic nextcloud-db \
  --from-literal=MYSQL_ROOT_PASSWORD=$DB_PASSWORD \
  --from-literal=MYSQL_PASSWORD=$DB_PASSWORD \
  --from-literal=MYSQL_DATABASE=nextcloud \
  --from-literal=MYSQL_USER=nextcloud \
  --from-literal=MYSQL_HOST=mariadb

# 3. Secret verifizieren
kubectl get secrets

# 4. Secret-Details anzeigen (Werte sind Base64-kodiert)
kubectl describe secret nextcloud-db

# 5. Einen Wert dekodieren (zum Testen)
kubectl get secret nextcloud-db -o jsonpath='{.data.MYSQL_PASSWORD}' | base64 -d
echo
```

**Erwartetes Ergebnis:**
```
NAME            TYPE     DATA   AGE
nextcloud-db    Opaque   5      10s
```

**Was passiert hier?**
1. `openssl rand -base64 32` generiert ein 32-Zeichen Base64-Passwort
2. `kubectl create secret generic` erstellt ein Secret mit 5 Key-Value-Paaren:
   - `MYSQL_ROOT_PASSWORD`: Root-Passwort fÃ¼r MariaDB
   - `MYSQL_PASSWORD`: Passwort fÃ¼r Nextcloud-User
   - `MYSQL_DATABASE`: Name der Datenbank
   - `MYSQL_USER`: Datenbank-User fÃ¼r Nextcloud
   - `MYSQL_HOST`: Hostname des MariaDB-Service

**Sicherheitshinweis:**
- Secret ist **nicht verschlÃ¼sselt** in etcd gespeichert!
- FÃ¼r Produktion: Encryption at rest aktivieren oder externe LÃ¶sung (Vault, Sealed Secrets)
- Niemals Secrets in Git committen!

---

### 4.3 MariaDB Deployment erstellen

#### Was ist ein Deployment?

Ein **Deployment** ist eine Kubernetes-Ressource, die:
- Pods erstellt und verwaltet
- Self-Healing bietet (Pod stirbt â†’ neuer Pod wird erstellt)
- Updates ermÃ¶glicht (Rolling Updates)

**Wichtig:** In **Stufe 2** werden wir MariaDB von Deployment auf **StatefulSet** umstellen (bessere Konsistenz fÃ¼r Datenbanken).

#### MariaDB-Deployment YAML

Erstellen Sie eine Datei `mariadb-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mariadb
  namespace: nextcloud-prod
  labels:
    app: mariadb
    tier: database
spec:
  replicas: 1  # Nur 1 Replica (Stufe 1)
  selector:
    matchLabels:
      app: mariadb
  template:
    metadata:
      labels:
        app: mariadb
        tier: database
    spec:
      containers:
      - name: mariadb
        image: docker.io/library/mariadb:10.11
        ports:
        - containerPort: 3306
          name: mysql
        env:
        # Alle Environment-Variablen kommen aus dem Secret
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_ROOT_PASSWORD
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_DATABASE
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_USER
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_PASSWORD
        volumeMounts:
        - name: mariadb-data
          mountPath: /var/lib/mysql
      volumes:
      - name: mariadb-data
        persistentVolumeClaim:
          claimName: mariadb-data
```

#### Persistent Volume Claim (PVC) fÃ¼r MariaDB

Erstellen Sie eine Datei `mariadb-pvc.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-data
  namespace: nextcloud-prod
spec:
  accessModes:
  - ReadWriteOnce  # RWO: Nur von einem Node nutzbar
  resources:
    requests:
      storage: 5Gi
  # StorageClass wird automatisch gewÃ¤hlt (default)
```

**Was ist ein PVC?**
- **PersistentVolumeClaim** = Anfrage fÃ¼r Speicher
- Kubernetes erstellt automatisch ein **PersistentVolume** (PV)
- Daten bleiben erhalten, auch wenn Pod neu erstellt wird

**Access Modes erklÃ¤rt:**
- **ReadWriteOnce (RWO)**: Nur 1 Node kann lesen/schreiben (ideal fÃ¼r Datenbanken)
- **ReadWriteMany (RWX)**: Mehrere Nodes kÃ¶nnen lesen/schreiben (ideal fÃ¼r gemeinsame Dateien)
- **ReadOnlyMany (ROX)**: Mehrere Nodes nur lesen

#### Deployment durchfÃ¼hren

```bash
# 1. PVC erstellen
kubectl apply -f mariadb-pvc.yaml

# 2. PVC-Status prÃ¼fen (sollte 'Pending' sein)
kubectl get pvc

# 3. Deployment erstellen
kubectl apply -f mariadb-deployment.yaml

# 4. PVC-Status erneut prÃ¼fen (jetzt 'Bound')
kubectl get pvc
# OUTPUT:
# NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES
# mariadb-data   Bound    pvc-abc123-def456-ghi789-jkl012-mno345    5Gi        RWO

# 5. Pod-Status prÃ¼fen
kubectl get pods
# OUTPUT:
# NAME                       READY   STATUS    RESTARTS   AGE
# mariadb-5d8f9c6b7d-abc12   1/1     Running   0          30s

# 6. Logs prÃ¼fen (MariaDB-Initialisierung)
kubectl logs -f deployment/mariadb
# Warten bis: "mysqld: ready for connections"
```

**Was passiert hier?**

1. **PVC wird erstellt:**
   - Kubernetes reserviert 5Gi Speicher
   - Status: `Pending` (noch nicht an Pod gebunden)

2. **Deployment erstellt Pod:**
   - Pod wird auf einem Node geplant
   - Container-Image `mariadb:10.11` wird heruntergeladen
   - Environment-Variablen werden aus Secret gelesen

3. **Volume wird gemountet:**
   - PVC wird an Pod gebunden â†’ Status: `Bound`
   - Volume wird unter `/var/lib/mysql` im Container gemountet

4. **MariaDB initialisiert:**
   - Datenbank `nextcloud` wird erstellt
   - User `nextcloud` mit Passwort wird angelegt
   - MariaDB ist bereit fÃ¼r Connections

**Troubleshooting:**

```bash
# Pod startet nicht?
kubectl describe pod -l app=mariadb

# Pod crasht?
kubectl logs -l app=mariadb --previous

# PVC bleibt 'Pending'?
kubectl describe pvc mariadb-data
# â†’ PrÃ¼fen ob StorageClass verfÃ¼gbar ist
```

---

### 4.4 MariaDB Service erstellen

#### Was ist ein Service?

Ein **Service** ist ein stabiler Netzwerk-Endpoint fÃ¼r Pods:
- Pods haben dynamische IPs (Ã¤ndern sich bei Neustart)
- Service hat stabile IP (ClusterIP)
- DNS-Name: `<service-name>.<namespace>.svc.cluster.local`

#### Service YAML

Erstellen Sie `mariadb-service.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mariadb
  namespace: nextcloud-prod
  labels:
    app: mariadb
spec:
  type: ClusterIP  # Nur innerhalb des Clusters erreichbar
  ports:
  - port: 3306
    targetPort: 3306
    protocol: TCP
    name: mysql
  selector:
    app: mariadb  # Alle Pods mit diesem Label werden angesprochen
```

#### Service deployen

```bash
# 1. Service erstellen
kubectl apply -f mariadb-service.yaml

# 2. Service prÃ¼fen
kubectl get service mariadb
# OUTPUT:
# NAME      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
# mariadb   ClusterIP   10.96.100.50    <none>        3306/TCP   10s

# 3. Endpoints prÃ¼fen (zeigt Pod-IPs)
kubectl get endpoints mariadb
# OUTPUT:
# NAME      ENDPOINTS           AGE
# mariadb   10.244.1.5:3306     10s

# 4. DNS-AuflÃ¶sung testen
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup mariadb
# OUTPUT:
# Server:    10.96.0.10
# Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
#
# Name:      mariadb
# Address 1: 10.96.100.50 mariadb.nextcloud-prod.svc.cluster.local
```

**Was passiert hier?**

1. **Service erstellt ClusterIP:**
   - Kubernetes weist eine stabile IP zu (z.B. `10.96.100.50`)
   - Diese IP Ã¤ndert sich nie (solange Service existiert)

2. **Selector findet Pods:**
   - Service sucht alle Pods mit Label `app: mariadb`
   - FÃ¼gt deren IPs zu Endpoints hinzu

3. **DNS-Eintrag wird erstellt:**
   - `mariadb` â†’ `10.96.100.50` (innerhalb Namespace)
   - `mariadb.nextcloud-prod.svc.cluster.local` â†’ `10.96.100.50` (vollstÃ¤ndiger Name)

4. **Load Balancing:**
   - Wenn mehrere Pods existieren (spÃ¤ter in Stufe 2), verteilt Service Traffic automatisch

**Nextcloud kann jetzt mit MariaDB verbinden Ã¼ber:**
- Hostname: `mariadb`
- Port: `3306`

---

### 4.5 Nextcloud Deployment erstellen

#### Nextcloud PVC (ReadWriteMany!)

**Wichtig:** Nextcloud benÃ¶tigt **ReadWriteMany** (RWX), weil spÃ¤ter mehrere Pods auf dieselben Dateien zugreifen.

Erstellen Sie `nextcloud-pvc.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nextcloud-data
  namespace: nextcloud-prod
spec:
  accessModes:
  - ReadWriteMany  # RWX: Mehrere Pods kÃ¶nnen gleichzeitig zugreifen
  resources:
    requests:
      storage: 5Gi
```

**Achtung:** Nicht alle StorageClasses unterstÃ¼tzen RWX!

```bash
# StorageClass-FÃ¤higkeiten prÃ¼fen
kubectl get storageclasses -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.allowVolumeExpansion}{"\n"}{end}'

# Wenn Ihre StorageClass kein RWX unterstÃ¼tzt:
# Option 1: NFS-StorageClass installieren
# Option 2: FÃ¼r Stufe 1: RWO verwenden (dann nur 1 Nextcloud-Replica mÃ¶glich)
```

#### Nextcloud Deployment YAML

Erstellen Sie `nextcloud-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nextcloud
  namespace: nextcloud-prod
  labels:
    app: nextcloud
    tier: frontend
spec:
  replicas: 1  # Stufe 1: Nur 1 Replica
  selector:
    matchLabels:
      app: nextcloud
  template:
    metadata:
      labels:
        app: nextcloud
        tier: frontend
    spec:
      containers:
      - name: nextcloud
        image: docker.io/library/nextcloud:28-apache
        ports:
        - containerPort: 80
          name: http
        env:
        # Datenbank-Verbindung
        - name: MYSQL_HOST
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_HOST
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_DATABASE
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_USER
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_PASSWORD
        # Nextcloud-spezifische Einstellungen
        - name: NEXTCLOUD_TRUSTED_DOMAINS
          value: "localhost nextcloud.local"
        - name: APACHE_DISABLE_REWRITE_IP
          value: "1"
        volumeMounts:
        - name: nextcloud-data
          mountPath: /var/www/html
      volumes:
      - name: nextcloud-data
        persistentVolumeClaim:
          claimName: nextcloud-data
```

**Environment-Variablen erklÃ¤rt:**

| Variable | Zweck |
|----------|-------|
| `MYSQL_HOST` | Hostname des MariaDB-Service (`mariadb`) |
| `MYSQL_DATABASE` | Datenbank-Name (`nextcloud`) |
| `MYSQL_USER` | Datenbank-User (`nextcloud`) |
| `MYSQL_PASSWORD` | Datenbank-Passwort (aus Secret) |
| `NEXTCLOUD_TRUSTED_DOMAINS` | Erlaubte Domains (wichtig fÃ¼r Security!) |
| `APACHE_DISABLE_REWRITE_IP` | Deaktiviert IP-Rewrite (fÃ¼r Ingress) |

#### Deployment durchfÃ¼hren

```bash
# 1. PVC erstellen
kubectl apply -f nextcloud-pvc.yaml

# 2. Deployment erstellen
kubectl apply -f nextcloud-deployment.yaml

# 3. Pod-Status beobachten (Initialisierung dauert 2-3 Minuten!)
kubectl get pods -w
# DrÃ¼cken Sie Ctrl+C wenn Pod 'Running' ist

# 4. Logs verfolgen (Nextcloud-Setup)
kubectl logs -f deployment/nextcloud

# Warten bis Sie sehen:
# "AH00163: Apache/2.4.XX (Debian) PHP/8.X.X configured"
# "Nextcloud was successfully installed"
```

**Was passiert wÃ¤hrend der Initialisierung?**

1. **Nextcloud-Container startet:**
   - Apache-Webserver startet
   - PHP-Module werden geladen

2. **Verbindung zu MariaDB:**
   - Nextcloud verbindet zu `mariadb:3306`
   - PrÃ¼ft ob Datenbank `nextcloud` existiert

3. **Erstmalige Installation:**
   - Nextcloud-Datenbank-Schema wird erstellt
   - Admin-User wird vorbereitet
   - Konfiguration in `/var/www/html/config/config.php`

4. **Bereit fÃ¼r Zugriff:**
   - Nextcloud-Webinterface ist verfÃ¼gbar

**Troubleshooting:**

```bash
# Pod startet nicht?
kubectl describe pod -l app=nextcloud

# Verbindung zu MariaDB schlÃ¤gt fehl?
kubectl logs -l app=nextcloud | grep -i mysql
kubectl exec -it deployment/nextcloud -- ping mariadb

# Initialisierung hÃ¤ngt?
kubectl exec -it deployment/nextcloud -- cat /var/www/html/config/config.php
```

---

### 4.6 Nextcloud Service erstellen

Erstellen Sie `nextcloud-service.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nextcloud
  namespace: nextcloud-prod
  labels:
    app: nextcloud
spec:
  type: ClusterIP  # Stufe 1: Interner Zugriff
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  selector:
    app: nextcloud
```

```bash
# Service erstellen
kubectl apply -f nextcloud-service.yaml

# Service prÃ¼fen
kubectl get service nextcloud
```

---

### 4.7 Zugriff auf Nextcloud (Port-Forwarding)

Da wir in Stufe 1 noch keinen Ingress haben, nutzen wir **Port-Forwarding** fÃ¼r lokalen Zugriff:

```bash
# Port-Forwarding starten (Terminal bleibt offen!)
kubectl port-forward service/nextcloud 8080:80

# In neuem Terminal oder Browser:
# http://localhost:8080
```

**Nextcloud Setup-Assistent:**

1. Browser Ã¶ffnen: `http://localhost:8080`
2. Admin-Account erstellen:
   - Username: `admin`
   - Passwort: (starkes Passwort wÃ¤hlen!)
3. "Empfohlene Apps installieren" (optional)
4. Klick auf "Installation abschlieÃŸen"

**GlÃ¼ckwunsch!** ğŸ‰ Nextcloud lÃ¤uft jetzt auf Kubernetes!

---

### 4.8 Stufe 1 - Abschluss & Verifikation

#### VollstÃ¤ndiger Status-Check

```bash
# Alle Ressourcen anzeigen
kubectl get all -n nextcloud-prod

# Erwartetes Ergebnis:
# NAME                             READY   STATUS    RESTARTS   AGE
# pod/mariadb-xxx                  1/1     Running   0          10m
# pod/nextcloud-xxx                1/1     Running   0          8m
#
# NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
# service/mariadb     ClusterIP   10.96.100.50    <none>        3306/TCP   10m
# service/nextcloud   ClusterIP   10.96.200.100   <none>        80/TCP     8m
#
# NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
# deployment.apps/mariadb     1/1     1            1           10m
# deployment.apps/nextcloud   1/1     1            1           8m

# PVCs prÃ¼fen
kubectl get pvc

# Erwartetes Ergebnis:
# NAME             STATUS   VOLUME        CAPACITY   ACCESS MODES
# mariadb-data     Bound    pvc-xxx       5Gi        RWO
# nextcloud-data   Bound    pvc-yyy       5Gi        RWX

# Secrets prÃ¼fen
kubectl get secrets

# Events prÃ¼fen (letzte Probleme?)
kubectl get events --sort-by='.lastTimestamp' | tail -20
```

#### Funktionstest

1. **Datei hochladen:**
   - Klick auf "+" â†’ "Datei hochladen"
   - Kleine Testdatei hochladen
   - PrÃ¼fen ob Datei erscheint

2. **Persistenz testen:**
   ```bash
   # Nextcloud-Pod lÃ¶schen
   kubectl delete pod -l app=nextcloud

   # Neuer Pod wird automatisch erstellt
   kubectl get pods -w

   # Port-Forwarding neu starten
   kubectl port-forward service/nextcloud 8080:80

   # Browser: http://localhost:8080
   # â†’ Datei sollte noch da sein!
   ```

3. **Datenbank-Persistenz testen:**
   ```bash
   # MariaDB-Pod lÃ¶schen
   kubectl delete pod -l app=mariadb

   # Warten bis neuer Pod 'Running'
   kubectl get pods -w

   # Nextcloud neu laden â†’ sollte funktionieren
   ```

#### Was Sie erreicht haben (Stufe 1)

âœ… Funktionierendes Nextcloud + MariaDB auf Kubernetes
âœ… Persistenter Storage (Daten bleiben erhalten)
âœ… Self-Healing (Pods werden automatisch neu erstellt)
âœ… Grundlegendes VerstÃ¤ndnis von:
- Namespaces
- Secrets
- Deployments
- Services
- PersistentVolumeClaims

#### Limitierungen von Stufe 1

âŒ Keine HochverfÃ¼gbarkeit (nur 1 Replica)
âŒ Kein externer Zugriff (nur Port-Forwarding)
âŒ Keine Resource Limits (kann alle Node-Ressourcen verbrauchen)
âŒ Keine Health Checks (Kubernetes weiÃŸ nicht ob Nextcloud "gesund" ist)
âŒ Keine Security-Features (Netzwerk-Isolation, TLS)
âŒ Kein Monitoring/Logging

**â†’ Stufe 2 behebt diese Limitierungen!**

---

## 5. Stufe 2: Production-Ready Features

### Ãœbersicht Stufe 2

In dieser Stufe machen wir Nextcloud **produktionsreif**:
- âœ… **HochverfÃ¼gbarkeit**: Mehrere Nextcloud-Replicas
- âœ… **StatefulSet fÃ¼r MariaDB**: Stabile Pod-IdentitÃ¤t
- âœ… **Resource Management**: CPU/Memory Limits
- âœ… **Health Checks**: Liveness & Readiness Probes
- âœ… **Security**: Network Policies, Pod Security
- âœ… **Externer Zugriff**: LoadBalancer Service

**Zeitaufwand:** ~30-40 Minuten
**Voraussetzung:** Abgeschlossene Stufe 1

---

### 5.1 MariaDB: Von Deployment zu StatefulSet

#### Warum StatefulSet fÃ¼r Datenbanken?

**Problem mit Deployments fÃ¼r Datenbanken:**
- Pod-Namen sind zufÃ¤llig (`mariadb-abc123`)
- Bei Neustart: Neuer Name, neue IP
- Schwierig fÃ¼r Master-Slave-Replikation
- Kein garantiertes Startup-/Shutdown-Verhalten

**Vorteile von StatefulSets:**
- âœ… Feste Pod-Namen (`mariadb-0`, `mariadb-1`)
- âœ… Stabile Netzwerk-IdentitÃ¤t
- âœ… Sequentielles Startup (0 â†’ 1 â†’ 2)
- âœ… Jeder Pod bekommt eigenen PVC
- âœ… Ideal fÃ¼r Datenbanken, Kafka, ZooKeeper

```
Deployment:                  StatefulSet:
mariadb-abc123 (zufÃ¤llig)   mariadb-0 (fix)
mariadb-def456              mariadb-1
mariadb-ghi789              mariadb-2
```

#### MariaDB StatefulSet YAML

**Wichtig:** Wir lÃ¶schen erst das alte Deployment und erstellen dann das StatefulSet.

Erstellen Sie `mariadb-statefulset.yaml`:

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mariadb
  namespace: nextcloud-prod
  labels:
    app: mariadb
    tier: database
spec:
  serviceName: mariadb  # Headless Service (wird erstellt)
  replicas: 1  # Stufe 2: Erstmal 1 Replica (spÃ¤ter skalierbar)
  selector:
    matchLabels:
      app: mariadb
  template:
    metadata:
      labels:
        app: mariadb
        tier: database
    spec:
      containers:
      - name: mariadb
        image: docker.io/library/mariadb:10.11
        ports:
        - containerPort: 3306
          name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_ROOT_PASSWORD
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_DATABASE
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_USER
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_PASSWORD
        # NEU: Resource Limits
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
        # NEU: Liveness Probe (ist DB am Leben?)
        livenessProbe:
          exec:
            command:
            - bash
            - -c
            - "mysqladmin ping -u root -p$MYSQL_ROOT_PASSWORD"
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # NEU: Readiness Probe (ist DB bereit?)
        readinessProbe:
          exec:
            command:
            - bash
            - -c
            - "mysql -u root -p$MYSQL_ROOT_PASSWORD -e 'SELECT 1'"
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: mariadb-data
          mountPath: /var/lib/mysql
  # NEU: volumeClaimTemplates (automatische PVC-Erstellung pro Pod)
  volumeClaimTemplates:
  - metadata:
      name: mariadb-data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi  # Mehr Storage fÃ¼r Production
```

**Neue Konzepte erklÃ¤rt:**

1. **serviceName: mariadb**
   - StatefulSet benÃ¶tigt einen Headless Service
   - ErmÃ¶glicht stabile DNS-Namen: `mariadb-0.mariadb.nextcloud-prod.svc.cluster.local`

2. **resources (Requests & Limits)**
   ```yaml
   requests:  # Garantierte Ressourcen
     cpu: 500m      # 0.5 CPU-Cores
     memory: 512Mi  # 512 Megabyte
   limits:    # Maximum
     cpu: 1000m     # 1 CPU-Core
     memory: 2Gi    # 2 Gigabyte
   ```
   - **Requests**: Kubernetes plant Pod nur auf Node mit freien Ressourcen
   - **Limits**: Pod wird gedrosselt (CPU) oder beendet (Memory) bei Ãœberschreitung

3. **Liveness Probe**
   - PrÃ¼ft: Ist Container "am Leben"?
   - Befehl: `mysqladmin ping` â†’ Exit Code 0 = gesund
   - Bei Fehler: Container wird neu gestartet
   - `initialDelaySeconds: 30` â†’ Warte 30s nach Container-Start
   - `periodSeconds: 10` â†’ PrÃ¼fe alle 10 Sekunden
   - `failureThreshold: 3` â†’ Nach 3 Fehlern neu starten

4. **Readiness Probe**
   - PrÃ¼ft: Ist Container "bereit" fÃ¼r Traffic?
   - Befehl: `mysql -e 'SELECT 1'` â†’ Kann DB Queries verarbeiten?
   - Bei Fehler: Pod wird aus Service-Endpoints entfernt (bekommt keinen Traffic)

5. **volumeClaimTemplates**
   - Erstellt automatisch PVC fÃ¼r jeden Pod
   - Pod `mariadb-0` â†’ PVC `mariadb-data-mariadb-0`
   - Pod `mariadb-1` â†’ PVC `mariadb-data-mariadb-1`

#### Migration: Deployment â†’ StatefulSet

**Achtung:** Dieser Prozess lÃ¶scht den Pod kurz (wenige Sekunden Downtime)!

```bash
# 1. Backup der aktuellen Konfiguration
kubectl get deployment mariadb -o yaml > mariadb-deployment-backup.yaml

# 2. Altes Deployment lÃ¶schen
kubectl delete deployment mariadb

# 3. Alten PVC lÃ¶schen (wird neu erstellt mit anderem Namen)
kubectl delete pvc mariadb-data

# 4. StatefulSet erstellen
kubectl apply -f mariadb-statefulset.yaml

# 5. Pod-Status beobachten
kubectl get pods -w
# Warten bis: mariadb-0   1/1   Running

# 6. PVC prÃ¼fen (neuer Name!)
kubectl get pvc
# OUTPUT:
# NAME                      STATUS   VOLUME   CAPACITY   ACCESS MODES
# mariadb-data-mariadb-0    Bound    pvc-xxx  20Gi       RWO

# 7. Logs prÃ¼fen
kubectl logs mariadb-0 -f
# Warten bis: "mysqld: ready for connections"
```

**Was ist passiert?**
1. Deployment gelÃ¶scht â†’ Pod `mariadb-abc123` beendet
2. StatefulSet erstellt â†’ Pod `mariadb-0` startet
3. PVC `mariadb-data-mariadb-0` automatisch erstellt
4. MariaDB initialisiert neu (âš ï¸ Datenbank-Daten sind weg!)

**âš ï¸ Datenverlust vermeiden:**

Wenn Sie Daten behalten wollen:
```bash
# Option A: Datenbank-Dump vor Migration
kubectl exec -it deployment/mariadb -- mysqldump -u root -p$DB_PASSWORD --all-databases > backup.sql

# Nach StatefulSet-Erstellung:
kubectl exec -it mariadb-0 -- mysql -u root -p$DB_PASSWORD < backup.sql

# Option B: PVC umbenennen (fortgeschritten)
kubectl get pvc mariadb-data -o yaml > old-pvc.yaml
# Editieren: name â†’ mariadb-data-mariadb-0
kubectl apply -f old-pvc.yaml
```

#### StatefulSet-Verhalten testen

```bash
# 1. Pod lÃ¶schen
kubectl delete pod mariadb-0

# 2. Neuer Pod wird erstellt (gleicher Name!)
kubectl get pods -w
# OUTPUT:
# NAME        READY   STATUS    RESTARTS   AGE
# mariadb-0   0/1     Pending   0          2s
# mariadb-0   1/1     Running   0          10s

# 3. Derselbe PVC wird wieder verwendet
kubectl describe pod mariadb-0 | grep ClaimName
# OUTPUT:
# ClaimName:  mariadb-data-mariadb-0
```

**Wichtig:** Der neue Pod `mariadb-0` verwendet **denselben PVC** â†’ Daten bleiben erhalten!

---

### 5.2 Nextcloud: HochverfÃ¼gbarkeit mit mehreren Replicas

#### Warum mehrere Replicas?

**Single Replica (Stufe 1):**
- âŒ Bei Pod-Ausfall: Downtime bis Neustart
- âŒ Keine Load-Verteilung
- âŒ Kein Rolling Update ohne Downtime

**Multi-Replica (Stufe 2):**
- âœ… Bei Pod-Ausfall: Andere Pods Ã¼bernehmen
- âœ… Load Balancing Ã¼ber mehrere Pods
- âœ… Rolling Updates ohne Downtime
- âœ… Horizontal skalierbar

#### Nextcloud Deployment (Production-Ready)

Erstellen Sie `nextcloud-deployment-ha.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nextcloud
  namespace: nextcloud-prod
  labels:
    app: nextcloud
    tier: frontend
spec:
  replicas: 3  # NEU: 3 Replicas fÃ¼r HA
  selector:
    matchLabels:
      app: nextcloud
  # NEU: Update-Strategie
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Max. 1 zusÃ¤tzlicher Pod wÃ¤hrend Update
      maxUnavailable: 0  # Kein Pod darf unavailable sein (keine Downtime!)
  template:
    metadata:
      labels:
        app: nextcloud
        tier: frontend
    spec:
      # NEU: Anti-Affinity (Pods auf verschiedene Nodes verteilen)
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: nextcloud
              topologyKey: kubernetes.io/hostname
      containers:
      - name: nextcloud
        image: docker.io/library/nextcloud:28-apache
        ports:
        - containerPort: 80
          name: http
        env:
        - name: MYSQL_HOST
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_HOST
        - name: MYSQL_DATABASE
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_DATABASE
        - name: MYSQL_USER
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_USER
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: nextcloud-db
              key: MYSQL_PASSWORD
        - name: NEXTCLOUD_TRUSTED_DOMAINS
          value: "localhost nextcloud.local nextcloud.yourdomain.com"
        - name: APACHE_DISABLE_REWRITE_IP
          value: "1"
        # NEU: Redis fÃ¼r Session-Sharing (spÃ¤ter erweitern)
        - name: REDIS_HOST
          value: "redis"  # Optional: Redis fÃ¼r Session-Storage
        # NEU: Resource Limits
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        # NEU: Liveness Probe (HTTP-Check)
        livenessProbe:
          httpGet:
            path: /status.php
            port: 80
            httpHeaders:
            - name: Host
              value: "localhost"
          initialDelaySeconds: 60  # Nextcloud braucht Zeit zum Starten
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # NEU: Readiness Probe
        readinessProbe:
          httpGet:
            path: /status.php
            port: 80
            httpHeaders:
            - name: Host
              value: "localhost"
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: nextcloud-data
          mountPath: /var/www/html
      volumes:
      - name: nextcloud-data
        persistentVolumeClaim:
          claimName: nextcloud-data
```

**Neue Konzepte erklÃ¤rt:**

1. **replicas: 3**
   - 3 unabhÃ¤ngige Nextcloud-Pods
   - Service verteilt Traffic Ã¼ber alle 3 (Load Balancing)

2. **Rolling Update Strategy**
   ```yaml
   maxSurge: 1        # WÃ¤hrend Update: Max. 4 Pods (3+1)
   maxUnavailable: 0  # Mindestens 3 Pods bleiben running
   ```
   **Ablauf bei Update:**
   - Start: 3 Pods (v1)
   - Update startet: 1 neuer Pod (v2) wird erstellt â†’ 4 Pods total
   - Warte bis neuer Pod 'Ready'
   - LÃ¶sche 1 alten Pod (v1) â†’ 3 Pods (2Ã—v1, 1Ã—v2)
   - Wiederhole bis alle Pods v2

3. **Pod Anti-Affinity**
   ```yaml
   podAntiAffinity:
     preferredDuringSchedulingIgnoredDuringExecution:
     - weight: 100
       podAffinityTerm:
         labelSelector:
           matchLabels:
             app: nextcloud
         topologyKey: kubernetes.io/hostname
   ```
   **Was macht das?**
   - "Versuche, Nextcloud-Pods auf **verschiedene Nodes** zu verteilen"
   - `preferred` = Soft Constraint (kein Zwang, aber bevorzugt)
   - `topologyKey: hostname` = Verteile basierend auf Node-Namen
   - **Vorteil:** Bei Node-Ausfall lÃ¤uft Nextcloud auf anderen Nodes weiter

4. **Liveness/Readiness Probes (HTTP)**
   ```yaml
   httpGet:
     path: /status.php  # Nextcloud-Status-Endpoint
     port: 80
     httpHeaders:
     - name: Host
       value: "localhost"
   ```
   - `/status.php` gibt JSON zurÃ¼ck: `{"installed":true,"maintenance":false}`
   - HTTP 200 = gesund
   - HTTP 5xx oder Timeout = ungesund

#### Deployment durchfÃ¼hren

```bash
# 1. Altes Deployment lÃ¶schen (falls vorhanden)
kubectl delete deployment nextcloud

# 2. Neues HA-Deployment erstellen
kubectl apply -f nextcloud-deployment-ha.yaml

# 3. Rollout-Status beobachten
kubectl rollout status deployment/nextcloud
# OUTPUT:
# Waiting for deployment "nextcloud" rollout to finish: 0 of 3 updated replicas are available...
# Waiting for deployment "nextcloud" rollout to finish: 1 of 3 updated replicas are available...
# Waiting for deployment "nextcloud" rollout to finish: 2 of 3 updated replicas are available...
# deployment "nextcloud" successfully rolled out

# 4. Pods prÃ¼fen
kubectl get pods -o wide
# OUTPUT:
# NAME                         READY   STATUS    RESTARTS   AGE   IP            NODE
# nextcloud-abc123             1/1     Running   0          2m    10.244.1.5    node1
# nextcloud-def456             1/1     Running   0          2m    10.244.2.8    node2
# nextcloud-ghi789             1/1     Running   0          2m    10.244.3.12   node3

# 5. Readiness-Status prÃ¼fen
kubectl get pods -l app=nextcloud -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
# Alle sollten "True" zeigen
```

**Was passiert?**
1. Kubernetes erstellt 3 Pods gleichzeitig
2. Jeder Pod:
   - Startet Nextcloud-Container
   - Mountet `/var/www/html` vom PVC (shared!)
   - Verbindet zu MariaDB
3. Readiness Probe prÃ¼ft `/status.php`
4. Nach 30s: Pods werden `Ready` â†’ bekommen Traffic vom Service

#### HochverfÃ¼gbarkeit testen

```bash
# 1. Baseline: Alle Pods laufen
kubectl get pods

# 2. Einen Pod lÃ¶schen (simuliert Crash)
kubectl delete pod nextcloud-abc123

# 3. Sofort wieder prÃ¼fen
kubectl get pods
# OUTPUT:
# nextcloud-abc123             0/1     Terminating   0          5m
# nextcloud-def456             1/1     Running       0          5m
# nextcloud-ghi789             1/1     Running       0          5m
# nextcloud-xyz999             0/1     ContainerCreating   0   2s  â† Neuer Pod!

# 4. Service-Endpoints (laufende Pods)
kubectl get endpoints nextcloud
# OUTPUT:
# NAME        ENDPOINTS                           AGE
# nextcloud   10.244.2.8:80,10.244.3.12:80        5m
# â†‘ Nur 2 IPs (gelÃ¶schter Pod wurde automatisch entfernt)

# 5. Nach ~30 Sekunden: Neuer Pod ist Ready
kubectl get pods
# nextcloud-def456             1/1     Running   0          6m
# nextcloud-ghi789             1/1     Running   0          6m
# nextcloud-xyz999             1/1     Running   0          30s

# 6. Service-Endpoints wieder vollstÃ¤ndig
kubectl get endpoints nextcloud
# Jetzt 3 IPs wieder
```

**Was ist passiert?**
1. Pod `abc123` stirbt â†’ Service entfernt ihn aus Endpoints
2. **Kein Traffic-Verlust:** Andere 2 Pods Ã¼bernehmen
3. ReplicaSet erstellt automatisch neuen Pod `xyz999`
4. Neuer Pod wird `Ready` â†’ Service fÃ¼gt ihn zu Endpoints hinzu
5. **Self-Healing komplett automatisch!**

---

### 5.3 Network Policies - Netzwerk-Isolation

#### Was sind Network Policies?

**Standardverhalten in Kubernetes:**
- âŒ Jeder Pod kann mit jedem Pod kommunizieren
- âŒ Keine Isolation zwischen Namespaces
- âŒ Sicherheitsrisiko!

**Mit Network Policies:**
- âœ… Whitelist-basierte Firewall-Regeln
- âœ… "Deny by default, allow specific"
- âœ… Pod-zu-Pod-Isolation
- âœ… Namespace-Isolation

#### Nextcloud Network Policies

Erstellen Sie `network-policies.yaml`:

```yaml
---
# 1. Deny-All Policy (Baseline)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: nextcloud-prod
spec:
  podSelector: {}  # Alle Pods im Namespace
  policyTypes:
  - Ingress
  - Egress

---
# 2. MariaDB Policy (nur Nextcloud darf verbinden)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: mariadb-allow-nextcloud
  namespace: nextcloud-prod
spec:
  podSelector:
    matchLabels:
      app: mariadb
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Erlaube Ingress nur von Nextcloud-Pods
  - from:
    - podSelector:
        matchLabels:
          app: nextcloud
    ports:
    - protocol: TCP
      port: 3306
  egress:
  # Erlaube DNS-AuflÃ¶sung
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53

---
# 3. Nextcloud Policy (Ingress von auÃŸen, Egress zu MariaDB)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: nextcloud-allow-web
  namespace: nextcloud-prod
spec:
  podSelector:
    matchLabels:
      app: nextcloud
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Erlaube HTTP/HTTPS von Ã¼berall
  - from: []  # Leere Liste = von Ã¼berall
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
  egress:
  # Erlaube Verbindung zu MariaDB
  - to:
    - podSelector:
        matchLabels:
          app: mariadb
    ports:
    - protocol: TCP
      port: 3306
  # Erlaube DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  # Erlaube Internet (fÃ¼r App-Updates, etc.)
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
```

**Policies erklÃ¤rt:**

1. **default-deny-all**
   ```yaml
   podSelector: {}  # Alle Pods
   policyTypes:
   - Ingress  # Kein eingehender Traffic
   - Egress   # Kein ausgehender Traffic
   ```
   - Baseline: Alles verboten
   - Andere Policies erlauben spezifische Verbindungen

2. **mariadb-allow-nextcloud**
   ```yaml
   ingress:
   - from:
     - podSelector:
         matchLabels:
           app: nextcloud  # Nur von Nextcloud-Pods
     ports:
     - port: 3306
   ```
   - MariaDB akzeptiert nur Verbindungen von Nextcloud
   - Port 3306 (MySQL)
   - **Sicherheit:** Andere Pods im Cluster kÃ¶nnen NICHT auf DB zugreifen

3. **nextcloud-allow-web**
   ```yaml
   ingress:
   - from: []  # Von Ã¼berall
     ports:
     - port: 80
   ```
   - Nextcloud akzeptiert HTTP/HTTPS von Ã¼berall
   - Kann zu MariaDB verbinden (Egress)
   - Kann Internet erreichen (fÃ¼r Updates)

#### Network Policies deployen

```bash
# 1. Policies erstellen
kubectl apply -f network-policies.yaml

# 2. Policies prÃ¼fen
kubectl get networkpolicies

# OUTPUT:
# NAME                       POD-SELECTOR   AGE
# default-deny-all           <none>         10s
# mariadb-allow-nextcloud    app=mariadb    10s
# nextcloud-allow-web        app=nextcloud  10s

# 3. Policy-Details
kubectl describe networkpolicy mariadb-allow-nextcloud
```

#### Network Policies testen

```bash
# 1. Baseline-Test: Nextcloud â†’ MariaDB (sollte funktionieren)
kubectl exec -it deployment/nextcloud -- nc -zv mariadb 3306
# OUTPUT:
# Connection to mariadb 3306 port [tcp/mysql] succeeded!

# 2. Negative Test: Debug-Pod â†’ MariaDB (sollte NICHT funktionieren)
kubectl run debug --image=busybox --rm -it --restart=Never -- sh
# Im Debug-Pod:
nc -zv mariadb.nextcloud-prod.svc.cluster.local 3306
# OUTPUT (nach Timeout):
# nc: mariadb.nextcloud-prod.svc.cluster.local (10.96.100.50:3306): Connection timed out

# 3. Positive Test: Internet-Zugriff von Nextcloud
kubectl exec -it deployment/nextcloud -- curl -I https://google.com
# OUTPUT:
# HTTP/2 200
```

**Was ist passiert?**
1. âœ… Nextcloud â†’ MariaDB: Erlaubt (durch `mariadb-allow-nextcloud`)
2. âŒ Debug-Pod â†’ MariaDB: Blockiert (durch `default-deny-all`)
3. âœ… Nextcloud â†’ Internet: Erlaubt (durch `nextcloud-allow-web` Egress)

**Sicherheits-Gewinn:**
- Selbst wenn Angreifer in Debug-Pod eindringt: **Kein Zugriff auf Datenbank**
- Lateral Movement im Cluster verhindert

---

### 5.4 LoadBalancer Service - Externer Zugriff

#### ClusterIP vs. LoadBalancer

**ClusterIP (Stufe 1):**
- Nur innerhalb des Clusters erreichbar
- Kein externer Zugriff
- Port-Forwarding notwendig

**LoadBalancer (Stufe 2):**
- Externe IP-Adresse (via MetalLB oder Cloud-Provider)
- Direkt von auÃŸen erreichbar
- Kein Port-Forwarding notwendig

#### Voraussetzung: MetalLB

Falls MetalLB nicht installiert ist (prÃ¼fen mit `kubectl get pods -n metallb-system`):

```bash
# MetalLB installieren (nur wenn nicht vorhanden)
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml

# IP-Pool konfigurieren
cat <<EOF | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: nextcloud-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.100.200-192.168.100.210  # Passen Sie IP-Range an!
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: nextcloud-l2
  namespace: metallb-system
spec:
  ipAddressPools:
  - nextcloud-pool
EOF
```

#### Nextcloud Service (LoadBalancer)

Erstellen Sie `nextcloud-service-lb.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nextcloud-lb
  namespace: nextcloud-prod
  labels:
    app: nextcloud
spec:
  type: LoadBalancer  # NEU: Externe IP
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    name: http
  selector:
    app: nextcloud
  # Optional: Spezifische IP anfordern
  # loadBalancerIP: 192.168.100.200
```

```bash
# 1. Service erstellen
kubectl apply -f nextcloud-service-lb.yaml

# 2. Service prÃ¼fen (warten bis EXTERNAL-IP erscheint)
kubectl get service nextcloud-lb -w
# OUTPUT:
# NAME           TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)        AGE
# nextcloud-lb   LoadBalancer   10.96.200.100   <pending>         80:31234/TCP   5s
# nextcloud-lb   LoadBalancer   10.96.200.100   192.168.100.200   80:31234/TCP   30s

# 3. Von anderem Rechner im Netzwerk zugreifen
curl http://192.168.100.200
# Oder Browser: http://192.168.100.200
```

**Was ist passiert?**
1. Service Typ `LoadBalancer` erstellt
2. MetalLB weist externe IP zu (aus Pool `192.168.100.200-210`)
3. MetalLB konfiguriert ARP-Responses (Layer 2)
4. Externe Clients kÃ¶nnen jetzt direkt auf `192.168.100.200` zugreifen
5. Traffic wird auf alle 3 Nextcloud-Pods verteilt

#### DNS konfigurieren (optional)

FÃ¼r schÃ¶nere URLs:

```bash
# /etc/hosts editieren (Linux/macOS)
echo "192.168.100.200 nextcloud.local" | sudo tee -a /etc/hosts

# Oder: DNS-Eintrag im Router/DNS-Server erstellen
# nextcloud.local â†’ 192.168.100.200

# Testen
curl http://nextcloud.local
```

---

### 5.5 Stufe 2 - Abschluss & Verifikation

#### VollstÃ¤ndiger Status-Check

```bash
# Alle Ressourcen
kubectl get all,pvc,secrets,networkpolicies,services

# StatefulSet prÃ¼fen
kubectl get statefulsets
# OUTPUT:
# NAME      READY   AGE
# mariadb   1/1     30m

# Deployment Replicas prÃ¼fen
kubectl get deployment nextcloud
# OUTPUT:
# NAME        READY   UP-TO-DATE   AVAILABLE   AGE
# nextcloud   3/3     3            3           20m

# Service mit externer IP
kubectl get service nextcloud-lb
# OUTPUT:
# NAME           TYPE           EXTERNAL-IP       PORT(S)
# nextcloud-lb   LoadBalancer   192.168.100.200   80:31234/TCP

# Resource-Verbrauch
kubectl top pods
# OUTPUT:
# NAME                       CPU(cores)   MEMORY(bytes)
# mariadb-0                  150m         450Mi
# nextcloud-abc123           200m         600Mi
# nextcloud-def456           180m         580Mi
# nextcloud-ghi789           190m         590Mi
```

#### Production-Readiness-Checkliste

âœ… **HochverfÃ¼gbarkeit:**
- [x] 3 Nextcloud-Replicas
- [x] StatefulSet fÃ¼r MariaDB
- [x] Anti-Affinity (Pods auf verschiedenen Nodes)
- [x] Rolling Updates ohne Downtime

âœ… **Resource Management:**
- [x] CPU/Memory Requests definiert
- [x] CPU/Memory Limits gesetzt
- [x] Pods kÃ¶nnen nicht alle Node-Ressourcen verbrauchen

âœ… **Health Checks:**
- [x] Liveness Probes (Auto-Restart bei Problemen)
- [x] Readiness Probes (Traffic nur an gesunde Pods)

âœ… **Security:**
- [x] Secrets fÃ¼r Credentials
- [x] Network Policies (Isolation)
- [x] Nicht-Root-User (Nextcloud-Image default)

âœ… **Netzwerk:**
- [x] LoadBalancer Service (externe IP)
- [x] Service Load-Balancing Ã¼ber 3 Pods
- [x] Stabile DNS-Namen

#### Load-Test

```bash
# Apache Bench (100 Requests, 10 concurrent)
ab -n 100 -c 10 http://192.168.100.200/status.php

# WÃ¤hrend des Tests: Resource-Verbrauch beobachten
kubectl top pods -l app=nextcloud

# Erwartetes Ergebnis:
# - Alle 3 Pods verarbeiten Requests (Last-Verteilung)
# - CPU/Memory bleibt unter Limits
```

#### Failover-Test

```bash
# 1. Terminal 1: Continuous Requests
while true; do curl -s http://192.168.100.200/status.php; sleep 1; done

# 2. Terminal 2: Pod lÃ¶schen
kubectl delete pod -l app=nextcloud --force --grace-period=0 | head -1

# 3. Terminal 1: Beobachten
# â†’ Maximal 1-2 Failed Requests
# â†’ Dann wieder erfolgreich (andere Pods Ã¼bernehmen)
```

**Erwartetes Ergebnis:**
- âœ… Minimale Downtime (1-2 Sekunden)
- âœ… Automatisches Self-Healing
- âœ… Neue Pods werden erstellt

---

## 6. Stufe 3: Monitoring & HA-Integration

### Ãœbersicht Stufe 3

In dieser Stufe integrieren wir Nextcloud mit dem **Enterprise-Cluster**:
- âœ… **TLS/HTTPS**: Cert-Manager fÃ¼r automatische Zertifikate
- âœ… **Ingress**: Nginx Ingress mit Domain
- âœ… **Monitoring**: Prometheus ServiceMonitor
- âœ… **Logging**: Loki-Integration
- âœ… **Backup**: Automatische Datenbank-Backups
- âœ… **Dashboards**: Grafana-Monitoring

**Zeitaufwand:** ~40-50 Minuten
**Voraussetzung:** Abgeschlossene Stufe 2 + HA-Cluster mit Monitoring-Stack

---

### 6.1 TLS mit Cert-Manager

#### Cert-Manager Voraussetzung prÃ¼fen

```bash
# Cert-Manager installiert?
kubectl get pods -n cert-manager

# ClusterIssuer vorhanden?
kubectl get clusterissuers
```

Falls nicht installiert, siehe HA-Cluster-Dokumentation oder:

```bash
# Cert-Manager installieren
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml

# Self-Signed ClusterIssuer (fÃ¼r Test)
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-issuer
spec:
  selfSigned: {}
EOF
```

#### Certificate Resource erstellen

Erstellen Sie `nextcloud-certificate.yaml`:

```yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: nextcloud-tls
  namespace: nextcloud-prod
spec:
  secretName: nextcloud-tls-secret
  duration: 2160h  # 90 Tage
  renewBefore: 360h  # Erneuern 15 Tage vorher
  subject:
    organizations:
    - Nextcloud Production
  commonName: nextcloud.yourdomain.com
  dnsNames:
  - nextcloud.yourdomain.com
  - nextcloud.local
  issuerRef:
    name: selfsigned-issuer  # Oder: letsencrypt-prod
    kind: ClusterIssuer
```

**FÃ¼r Let's Encrypt (Production):**

```yaml
---
# Let's Encrypt ClusterIssuer
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: your-email@example.com  # â† Ã„ndern!
    privateKeySecretRef:
      name: letsencrypt-prod-account-key
    solvers:
    - http01:
        ingress:
          class: nginx
---
# Certificate mit Let's Encrypt
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: nextcloud-tls
  namespace: nextcloud-prod
spec:
  secretName: nextcloud-tls-secret
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  dnsNames:
  - nextcloud.yourdomain.com  # â† Ã„ndern zu Ihrer Domain!
```

```bash
# Certificate erstellen
kubectl apply -f nextcloud-certificate.yaml

# Status prÃ¼fen
kubectl get certificate -n nextcloud-prod
# OUTPUT:
# NAME            READY   SECRET                  AGE
# nextcloud-tls   True    nextcloud-tls-secret    30s

# Secret prÃ¼fen (enthÃ¤lt TLS-Zertifikat)
kubectl get secret nextcloud-tls-secret -o yaml
```

**Was ist passiert?**
1. Cert-Manager erstellt Private Key
2. Certificate Signing Request (CSR) wird erstellt
3. Let's Encrypt validiert Domain (HTTP-01 Challenge via Ingress)
4. Zertifikat wird ausgestellt
5. Secret `nextcloud-tls-secret` enthÃ¤lt:
   - `tls.crt`: Zertifikat
   - `tls.key`: Private Key

---

### 6.2 Ingress mit TLS

#### Nginx Ingress Controller prÃ¼fen

```bash
# Ingress Controller installiert?
kubectl get pods -n ingress-nginx

# IngressClass verfÃ¼gbar?
kubectl get ingressclasses
```

#### Ingress Resource erstellen

Erstellen Sie `nextcloud-ingress.yaml`:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nextcloud
  namespace: nextcloud-prod
  annotations:
    # Nginx-spezifische Einstellungen
    nginx.ingress.kubernetes.io/proxy-body-size: "10g"  # Max. Upload-GrÃ¶ÃŸe
    nginx.ingress.kubernetes.io/proxy-buffering: "off"
    nginx.ingress.kubernetes.io/server-snippet: |
      location = /.well-known/carddav {
        return 301 $scheme://$host/remote.php/dav;
      }
      location = /.well-known/caldav {
        return 301 $scheme://$host/remote.php/dav;
      }
    # Cert-Manager Annotation
    cert-manager.io/cluster-issuer: "selfsigned-issuer"  # Oder: letsencrypt-prod
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - nextcloud.yourdomain.com  # â† Ã„ndern!
    secretName: nextcloud-tls-secret
  rules:
  - host: nextcloud.yourdomain.com  # â† Ã„ndern!
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nextcloud-lb  # Oder: nextcloud (ClusterIP Service)
            port:
              number: 80
```

**Annotations erklÃ¤rt:**

| Annotation | Zweck |
|------------|-------|
| `proxy-body-size: "10g"` | Max. 10GB Datei-Uploads |
| `proxy-buffering: "off"` | Streaming fÃ¼r groÃŸe Dateien |
| `server-snippet` | CalDAV/CardDAV Redirects fÃ¼r Nextcloud |
| `cert-manager.io/cluster-issuer` | Automatische TLS-Zertifikat-Erstellung |

```bash
# Ingress erstellen
kubectl apply -f nextcloud-ingress.yaml

# Ingress prÃ¼fen
kubectl get ingress nextcloud
# OUTPUT:
# NAME        CLASS   HOSTS                      ADDRESS           PORTS     AGE
# nextcloud   nginx   nextcloud.yourdomain.com   192.168.100.100   80, 443   30s

# Ingress-Details
kubectl describe ingress nextcloud
```

#### HTTPS testen

```bash
# DNS/hosts konfigurieren (falls nÃ¶tig)
echo "192.168.100.100 nextcloud.yourdomain.com" | sudo tee -a /etc/hosts

# HTTP â†’ HTTPS Redirect testen
curl -I http://nextcloud.yourdomain.com
# OUTPUT:
# HTTP/1.1 308 Permanent Redirect
# Location: https://nextcloud.yourdomain.com/

# HTTPS testen
curl -k https://nextcloud.yourdomain.com/status.php
# OUTPUT:
# {"installed":true,"maintenance":false,...}

# Browser: https://nextcloud.yourdomain.com
```

#### Nextcloud Trusted Domains aktualisieren

Nextcloud muss die neue Domain kennen:

```bash
# Option 1: Environment-Variable (Deployment aktualisieren)
kubectl set env deployment/nextcloud NEXTCLOUD_TRUSTED_DOMAINS="nextcloud.yourdomain.com"

# Option 2: Direkt in config.php (temporÃ¤r)
kubectl exec -it deployment/nextcloud -- bash
# Im Container:
vi /var/www/html/config/config.php
# HinzufÃ¼gen:
# 'trusted_domains' =>
# array (
#   0 => 'localhost',
#   1 => 'nextcloud.yourdomain.com',
# ),
```

---

### 6.3 Prometheus Monitoring

#### ServiceMonitor erstellen

Erstellen Sie `nextcloud-servicemonitor.yaml`:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: nextcloud
  namespace: nextcloud-prod
  labels:
    app: nextcloud
spec:
  selector:
    matchLabels:
      app: nextcloud
  endpoints:
  - port: http
    interval: 30s
    path: /ocs/v2.php/apps/serverinfo/api/v1/info?format=json
    scheme: http
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mariadb
  namespace: nextcloud-prod
  labels:
    app: mariadb
spec:
  selector:
    matchLabels:
      app: mariadb
  endpoints:
  - port: mysql
    interval: 30s
```

**Wichtig:** Nextcloud benÃ¶tigt das **ServerInfo**-Plugin fÃ¼r Metriken:

```bash
# ServerInfo-App aktivieren (in Nextcloud-Pod)
kubectl exec -it deployment/nextcloud -- su -s /bin/bash www-data -c "php occ app:install serverinfo"
kubectl exec -it deployment/nextcloud -- su -s /bin/bash www-data -c "php occ app:enable serverinfo"

# ServiceMonitor erstellen
kubectl apply -f nextcloud-servicemonitor.yaml

# ServiceMonitor prÃ¼fen
kubectl get servicemonitors -n nextcloud-prod
```

#### Prometheus prÃ¼fen

```bash
# Prometheus UI Ã¶ffnen (Port-Forward)
kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090

# Browser: http://localhost:9090
# Targets prÃ¼fen: Status â†’ Targets
# Suche nach "nextcloud-prod/nextcloud" und "nextcloud-prod/mariadb"
```

**Metriken testen:**

In Prometheus UI â†’ Graph:
```promql
# Nextcloud-Uptime
up{job="nextcloud"}

# Anzahl Nextcloud-Users
nextcloud_users_total

# MariaDB-Verbindungen
mysql_global_status_threads_connected
```

---

### 6.4 Grafana Dashboard

#### Dashboard importieren

Erstellen Sie `nextcloud-dashboard.json` (vereinfachte Version):

```json
{
  "dashboard": {
    "title": "Nextcloud Production",
    "panels": [
      {
        "title": "Nextcloud Pods",
        "targets": [
          {
            "expr": "up{job=\"nextcloud\"}",
            "legendFormat": "{{pod}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "CPU Usage",
        "targets": [
          {
            "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"nextcloud-prod\"}[5m])) by (pod)",
            "legendFormat": "{{pod}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Memory Usage",
        "targets": [
          {
            "expr": "sum(container_memory_working_set_bytes{namespace=\"nextcloud-prod\"}) by (pod)",
            "legendFormat": "{{pod}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Active Users",
        "targets": [
          {
            "expr": "nextcloud_users_total",
            "legendFormat": "Total Users"
          }
        ],
        "type": "stat"
      }
    ]
  }
}
```

#### Dashboard in Grafana laden

```bash
# Grafana UI Ã¶ffnen
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Browser: http://localhost:3000
# Login: admin / (Passwort aus Secret)
kubectl get secret -n monitoring prometheus-grafana -o jsonpath='{.data.admin-password}' | base64 -d

# Dashboard importieren:
# 1. "+" â†’ "Import"
# 2. "Upload JSON file" â†’ nextcloud-dashboard.json
# 3. "Import"
```

**Alternative: ConfigMap fÃ¼r automatisches Laden**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nextcloud-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  nextcloud.json: |
    {... Dashboard JSON ...}
```

---

### 6.5 Backup-Strategie

#### Datenbank-Backup CronJob

Erstellen Sie `db-backup-cronjob.yaml`:

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mariadb-backup
  namespace: nextcloud-prod
spec:
  schedule: "0 2 * * *"  # TÃ¤glich um 2 Uhr nachts
  successfulJobsHistoryLimit: 7  # Behalte 7 erfolgreiche Backups
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: backup
            image: docker.io/library/mariadb:10.11
            env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nextcloud-db
                  key: MYSQL_ROOT_PASSWORD
            command:
            - /bin/bash
            - -c
            - |
              set -e
              BACKUP_FILE="/backup/nextcloud-$(date +%Y%m%d-%H%M%S).sql.gz"
              echo "Starting backup to $BACKUP_FILE"

              mysqldump -h mariadb -u root -p$MYSQL_ROOT_PASSWORD \
                --single-transaction \
                --routines \
                --triggers \
                --all-databases \
                | gzip > $BACKUP_FILE

              echo "Backup completed: $BACKUP_FILE"

              # Cleanup: LÃ¶sche Backups Ã¤lter als 7 Tage
              find /backup -name "nextcloud-*.sql.gz" -mtime +7 -delete

              echo "Old backups cleaned up"
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-storage
---
# PVC fÃ¼r Backups
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-storage
  namespace: nextcloud-prod
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
```

**CronJob-Optionen erklÃ¤rt:**

| Option | Wert | Bedeutung |
|--------|------|-----------|
| `schedule` | `0 2 * * *` | TÃ¤glich um 2:00 Uhr |
| `successfulJobsHistoryLimit` | `7` | Behalte letzte 7 erfolgreiche Jobs |
| `--single-transaction` | | Konsistentes Backup ohne DB-Lock |
| `--all-databases` | | Alle Datenbanken sichern |
| `gzip` | | Kompression (spart Speicher) |

#### Backup deployen und testen

```bash
# CronJob erstellen
kubectl apply -f db-backup-cronjob.yaml

# CronJob prÃ¼fen
kubectl get cronjobs

# Manuell triggern (zum Testen)
kubectl create job --from=cronjob/mariadb-backup manual-backup-1

# Job-Status
kubectl get jobs
kubectl logs job/manual-backup-1

# Backup-Dateien prÃ¼fen
kubectl exec -it deployment/nextcloud -- ls -lh /backup/
# Oder: Mount backup-storage PVC in Debug-Pod
```

#### Backup wiederherstellen

```bash
# 1. Backup-Liste anzeigen
kubectl exec -it deployment/nextcloud -- ls -lh /backup/

# 2. Backup wiederherstellen
BACKUP_FILE="nextcloud-20250115-020000.sql.gz"

kubectl exec -it mariadb-0 -- bash -c "
  zcat /backup/$BACKUP_FILE | mysql -u root -p\$MYSQL_ROOT_PASSWORD
"

# 3. Nextcloud-Pods neu starten
kubectl rollout restart deployment/nextcloud
```

---

### 6.6 Stufe 3 - Abschluss

#### Enterprise-Readiness-Checkliste

âœ… **TLS/Security:**
- [x] HTTPS mit Cert-Manager
- [x] Automatische Zertifikat-Erneuerung
- [x] Network Policies aktiv

âœ… **Monitoring:**
- [x] Prometheus ServiceMonitor
- [x] Grafana Dashboard
- [x] Metriken von Nextcloud + MariaDB

âœ… **Backup:**
- [x] Automatische tÃ¤gliche Backups
- [x] 7-Tage-Retention
- [x] Restore-Prozedur dokumentiert

âœ… **HochverfÃ¼gbarkeit:**
- [x] 3 Nextcloud-Replicas
- [x] Ingress mit Load Balancing
- [x] StatefulSet fÃ¼r MariaDB

âœ… **Zugriff:**
- [x] HTTPS-Domain (nextcloud.yourdomain.com)
- [x] Externe IP (MetalLB)
- [x] CalDAV/CardDAV Redirects

---

## 7. Backup & Restore

### 7.1 VollstÃ¤ndiges Backup

#### Was muss gesichert werden?

1. **Datenbank** (MariaDB)
   - Alle Nextcloud-Metadaten
   - User-Informationen
   - Shares, Permissions, etc.

2. **Nextcloud-Dateien** (PVC: nextcloud-data)
   - User-Uploads
   - Nextcloud-Apps
   - Konfiguration (`config/config.php`)

3. **Kubernetes-Manifeste**
   - Deployments, Services, Ingress
   - Secrets, ConfigMaps
   - Network Policies

#### Backup-Skript (vollstÃ¤ndig)

Erstellen Sie `backup-nextcloud-full.sh`:

```bash
#!/bin/bash
set -e

NAMESPACE="nextcloud-prod"
BACKUP_DIR="./backups/$(date +%Y%m%d-%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "=== Nextcloud Full Backup ==="
echo "Backup Directory: $BACKUP_DIR"

# 1. Kubernetes-Manifeste exportieren
echo "1. Exporting Kubernetes manifests..."
kubectl get all,pvc,secrets,ingress,networkpolicies,servicemonitors -n $NAMESPACE -o yaml > "$BACKUP_DIR/k8s-resources.yaml"

# 2. Datenbank-Backup
echo "2. Backing up MariaDB..."
DB_PASSWORD=$(kubectl get secret nextcloud-db -n $NAMESPACE -o jsonpath='{.data.MYSQL_ROOT_PASSWORD}' | base64 -d)

kubectl exec -n $NAMESPACE mariadb-0 -- bash -c "
  mysqldump -u root -p$DB_PASSWORD \
    --single-transaction \
    --routines \
    --triggers \
    --all-databases \
    | gzip
" > "$BACKUP_DIR/database.sql.gz"

# 3. Nextcloud-Dateien (PVC Snapshot oder Kopie)
echo "3. Creating PVC snapshot..."
# Option A: VolumeSnapshot (wenn unterstÃ¼tzt)
cat <<EOF | kubectl apply -f -
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: nextcloud-data-snapshot-$(date +%Y%m%d-%H%M%S)
  namespace: $NAMESPACE
spec:
  volumeSnapshotClassName: csi-hostpath-snapclass
  source:
    persistentVolumeClaimName: nextcloud-data
EOF

# Option B: Datei-Kopie (langsamer, aber universell)
# kubectl cp $NAMESPACE/nextcloud-pod:/var/www/html "$BACKUP_DIR/nextcloud-files"

echo "Backup completed: $BACKUP_DIR"
echo "Files:"
ls -lh "$BACKUP_DIR"
```

**Backup ausfÃ¼hren:**

```bash
chmod +x backup-nextcloud-full.sh
./backup-nextcloud-full.sh
```

---

### 7.2 Disaster Recovery

#### Kompletter Cluster-Restore

**Szenario:** Cluster ist komplett ausgefallen, Neuaufbau von Grund auf.

```bash
# 1. Namespace erstellen
kubectl create namespace nextcloud-prod

# 2. Secrets wiederherstellen (aus Backup)
kubectl apply -f backups/20250115-020000/k8s-resources.yaml

# 3. PVCs manuell erstellen (falls VolumeSnapshot nicht unterstÃ¼tzt)
kubectl apply -f mariadb-pvc.yaml
kubectl apply -f nextcloud-pvc.yaml

# 4. Datenbank-Daten wiederherstellen
# TemporÃ¤rer MariaDB-Pod fÃ¼r Restore
kubectl run mariadb-restore --image=mariadb:10.11 -n nextcloud-prod \
  --env MYSQL_ROOT_PASSWORD=temp123 \
  --overrides='
{
  "spec": {
    "containers": [{
      "name": "mariadb",
      "image": "mariadb:10.11",
      "volumeMounts": [{
        "name": "data",
        "mountPath": "/var/lib/mysql"
      }]
    }],
    "volumes": [{
      "name": "data",
      "persistentVolumeClaim": {
        "claimName": "mariadb-data-mariadb-0"
      }
    }]
  }
}'

# Warten bis Pod lÃ¤uft
kubectl wait --for=condition=ready pod/mariadb-restore -n nextcloud-prod --timeout=300s

# Backup in Pod kopieren
kubectl cp backups/20250115-020000/database.sql.gz nextcloud-prod/mariadb-restore:/tmp/

# Restore durchfÃ¼hren
kubectl exec -it mariadb-restore -n nextcloud-prod -- bash -c "
  zcat /tmp/database.sql.gz | mysql -u root -ptemp123
"

# Restore-Pod lÃ¶schen
kubectl delete pod mariadb-restore -n nextcloud-prod

# 5. StatefulSet + Deployment wiederherstellen
kubectl apply -f mariadb-statefulset.yaml
kubectl apply -f nextcloud-deployment-ha.yaml
kubectl apply -f nextcloud-service-lb.yaml
kubectl apply -f nextcloud-ingress.yaml

# 6. Verifizieren
kubectl get pods -n nextcloud-prod
```

---

## 8. Troubleshooting

### 8.1 HÃ¤ufige Probleme

#### Problem: Nextcloud-Pod startet nicht

**Symptome:**
```bash
kubectl get pods
# nextcloud-abc123   0/1   CrashLoopBackOff   5   10m
```

**Diagnose:**
```bash
# Logs prÃ¼fen
kubectl logs nextcloud-abc123

# Events prÃ¼fen
kubectl describe pod nextcloud-abc123

# HÃ¤ufige Ursachen:
# 1. Datenbank nicht erreichbar
kubectl exec -it nextcloud-abc123 -- ping mariadb

# 2. PVC nicht gemountet
kubectl describe pvc nextcloud-data

# 3. Resource Limits zu niedrig
kubectl top pod nextcloud-abc123
```

**LÃ¶sung:**
```bash
# Datenbank-Verbindung testen
kubectl run -it --rm debug --image=mysql:8 --restart=Never -- \
  mysql -h mariadb -u nextcloud -p

# PVC-Problem: StorageClass prÃ¼fen
kubectl get sc

# Resource-Limits erhÃ¶hen
kubectl set resources deployment/nextcloud \
  --limits=cpu=2,memory=2Gi \
  --requests=cpu=500m,memory=512Mi
```

---

#### Problem: "Trusted Domain" Fehler

**Symptome:**
Browser zeigt: "Access through untrusted domain"

**LÃ¶sung:**
```bash
# Option 1: Environment-Variable
kubectl set env deployment/nextcloud \
  NEXTCLOUD_TRUSTED_DOMAINS="localhost nextcloud.local nextcloud.yourdomain.com"

# Option 2: Manuell in config.php
kubectl exec -it deployment/nextcloud -- bash
vi /var/www/html/config/config.php
# HinzufÃ¼gen:
# 'trusted_domains' =>
# array (
#   0 => 'localhost',
#   1 => 'nextcloud.yourdomain.com',
# ),

# Pods neu starten
kubectl rollout restart deployment/nextcloud
```

---

#### Problem: Datei-Uploads schlagen fehl

**Symptome:**
"Error while uploading file" im Browser

**Diagnose:**
```bash
# Ingress Body-Size prÃ¼fen
kubectl describe ingress nextcloud | grep body-size

# PHP Memory Limit prÃ¼fen
kubectl exec -it deployment/nextcloud -- php -i | grep memory_limit
```

**LÃ¶sung:**
```bash
# Ingress Annotation erhÃ¶hen
kubectl annotate ingress nextcloud \
  nginx.ingress.kubernetes.io/proxy-body-size=10g --overwrite

# PHP Memory Limit erhÃ¶hen (Environment-Variable)
kubectl set env deployment/nextcloud PHP_MEMORY_LIMIT=512M
```

---

#### Problem: Langsame Performance

**Diagnose:**
```bash
# Resource-Verbrauch
kubectl top pods -n nextcloud-prod

# Anzahl Pods
kubectl get pods -l app=nextcloud

# PVC Performance (IOPS)
kubectl exec -it deployment/nextcloud -- bash
dd if=/dev/zero of=/var/www/html/testfile bs=1M count=100
# Sollte > 50 MB/s sein
```

**LÃ¶sung:**
```bash
# Mehr Replicas
kubectl scale deployment/nextcloud --replicas=5

# Resource-Limits erhÃ¶hen
kubectl set resources deployment/nextcloud \
  --limits=cpu=4,memory=4Gi \
  --requests=cpu=1,memory=1Gi

# Redis fÃ¼r Session-Caching hinzufÃ¼gen (fortgeschritten)
```

---

### 8.2 Debugging-Commands

```bash
# Alle Events im Namespace
kubectl get events -n nextcloud-prod --sort-by='.lastTimestamp'

# Pod-Logs (alle Container)
kubectl logs -l app=nextcloud --all-containers=true

# Interaktive Shell in Pod
kubectl exec -it deployment/nextcloud -- bash

# Datenbank-Verbindung testen
kubectl run -it --rm mysql-client --image=mysql:8 --restart=Never -- \
  mysql -h mariadb.nextcloud-prod.svc.cluster.local -u nextcloud -p

# DNS-AuflÃ¶sung testen
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  nslookup mariadb.nextcloud-prod.svc.cluster.local

# Network Policy testen
kubectl run -it --rm debug --image=nicolaka/netshoot --restart=Never -- bash
# Im Pod: nc -zv mariadb 3306
```

---

## 9. Wartung & Updates

### 9.1 Nextcloud-Update

#### Update-Prozess (Rolling Update)

```bash
# 1. Aktuelles Image-Version prÃ¼fen
kubectl get deployment nextcloud -o jsonpath='{.spec.template.spec.containers[0].image}'

# 2. Neue Version setzen
kubectl set image deployment/nextcloud nextcloud=docker.io/library/nextcloud:29-apache

# 3. Rollout beobachten
kubectl rollout status deployment/nextcloud

# 4. Rollout-Historie
kubectl rollout history deployment/nextcloud
```

**Was passiert?**
1. Kubernetes erstellt neuen Pod mit Version 29
2. Warte bis neuer Pod `Ready`
3. LÃ¶sche alten Pod mit Version 28
4. Wiederhole fÃ¼r alle Pods
5. **Keine Downtime** (maxUnavailable: 0)

#### Rollback bei Problemen

```bash
# Sofortiger Rollback zur vorherigen Version
kubectl rollout undo deployment/nextcloud

# Rollback zu spezifischer Revision
kubectl rollout history deployment/nextcloud
kubectl rollout undo deployment/nextcloud --to-revision=2
```

---

### 9.2 MariaDB-Update

**Achtung:** MariaDB-Updates sind komplexer (Datenbank-Schema-Migrationen)!

```bash
# 1. BACKUP ERSTELLEN!
./backup-nextcloud-full.sh

# 2. Maintenance Mode aktivieren
kubectl exec -it deployment/nextcloud -- su -s /bin/bash www-data -c "php occ maintenance:mode --on"

# 3. MariaDB-Image aktualisieren
kubectl set image statefulset/mariadb mariadb=docker.io/library/mariadb:10.12

# 4. Rollout beobachten (StatefulSet: Sequentiell!)
kubectl rollout status statefulset/mariadb

# 5. Datenbank-Upgrade (falls nÃ¶tig)
kubectl exec -it mariadb-0 -- mysql_upgrade -u root -p

# 6. Maintenance Mode deaktivieren
kubectl exec -it deployment/nextcloud -- su -s /bin/bash www-data -c "php occ maintenance:mode --off"
```

---

### 9.3 Kubernetes-Manifeste pflegen

**GitOps-Workflow (empfohlen):**

```bash
# 1. Alle Manifeste exportieren
kubectl get deployment,statefulset,service,ingress,pvc,networkpolicy \
  -n nextcloud-prod -o yaml > nextcloud-prod-manifests.yaml

# 2. Bereinigen (automatisch generierte Felder entfernen)
# Zu lÃ¶schen:
# - metadata.resourceVersion
# - metadata.uid
# - metadata.creationTimestamp
# - status (ganzer Block)
# - spec.clusterIP (Services)

# 3. In Git committen
git add nextcloud-prod-manifests.yaml
git commit -m "Update Nextcloud production manifests"
git push

# 4. Flux CD automatisch synchronisiert (wenn konfiguriert)
```

---

## 10. Best Practices

### 10.1 Security Best Practices

âœ… **Secrets Management:**
- Niemals Secrets in Git committen
- Rotation von PasswÃ¶rtern alle 90 Tage
- Externe Secret-Stores (Vault, Sealed Secrets)

âœ… **Network Policies:**
- "Deny by default, allow specific"
- RegelmÃ¤ÃŸig auditieren (`kubectl get networkpolicies`)

âœ… **RBAC:**
- Separate ServiceAccounts fÃ¼r Nextcloud/MariaDB
- Minimale Berechtigungen (Least Privilege)

âœ… **Pod Security:**
```yaml
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 33  # www-data
    fsGroup: 33
```

âœ… **Image Security:**
- Nur offizielle Images von Docker Hub
- Image-Tags mit Versionen (nicht `latest`)
- Vulnerability Scanning (Trivy, Clair)

---

### 10.2 Performance Best Practices

âœ… **Resource Tuning:**
```yaml
resources:
  requests:
    cpu: 1000m       # Basis-Last
    memory: 1Gi
  limits:
    cpu: 4000m       # 4x fÃ¼r Spitzen
    memory: 4Gi
```

âœ… **Horizontal Pod Autoscaling:**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nextcloud
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nextcloud
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

âœ… **Redis fÃ¼r Caching:**
```yaml
# Redis Deployment fÃ¼r Session-Storage
- name: REDIS_HOST
  value: redis
- name: REDIS_HOST_PORT
  value: "6379"
```

âœ… **PVC Performance:**
- SSD-basierte StorageClass
- ReadWriteMany (NFS) fÃ¼r Nextcloud-Dateien
- ReadWriteOnce (iSCSI/SAN) fÃ¼r MariaDB

---

### 10.3 Availability Best Practices

âœ… **Pod Disruption Budget:**
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nextcloud-pdb
spec:
  minAvailable: 2  # Mindestens 2 Pods wÃ¤hrend Wartung
  selector:
    matchLabels:
      app: nextcloud
```

âœ… **Liveness/Readiness Probes:**
```yaml
livenessProbe:
  httpGet:
    path: /status.php
    port: 80
  initialDelaySeconds: 60   # Genug Zeit fÃ¼r Startup
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3       # Nach 30s (3Ã—10s) neu starten

readinessProbe:
  httpGet:
    path: /status.php
    port: 80
  initialDelaySeconds: 10   # Schneller bereit als liveness
  periodSeconds: 5
  failureThreshold: 2       # Nach 10s (2Ã—5s) aus Endpoints
```

âœ… **Multi-AZ Deployment:**
```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:  # HARD constraint
    - labelSelector:
        matchLabels:
          app: nextcloud
      topologyKey: topology.kubernetes.io/zone  # Verschiedene Availability Zones
```

---

### 10.4 Backup Best Practices

âœ… **3-2-1 Rule:**
- **3** Kopien der Daten
- **2** verschiedene Speichermedien
- **1** Kopie off-site

âœ… **Automatisierung:**
- TÃ¤gliche automatische Backups (CronJob)
- WÃ¶chentliche vollstÃ¤ndige Backups
- Monatliche Archivierung

âœ… **Testing:**
```bash
# Monatlicher Restore-Test
# 1. Test-Namespace erstellen
kubectl create namespace nextcloud-restore-test

# 2. Backup wiederherstellen
./restore-backup.sh backups/20250115-020000 nextcloud-restore-test

# 3. FunktionalitÃ¤t prÃ¼fen
kubectl port-forward -n nextcloud-restore-test svc/nextcloud 8081:80
curl http://localhost:8081/status.php

# 4. Test-Namespace lÃ¶schen
kubectl delete namespace nextcloud-restore-test
```

---

## Zusammenfassung

### Was Sie erreicht haben

Nach Abschluss aller 3 Stufen haben Sie:

âœ… **Stufe 1 - Basis:**
- Funktionierende Nextcloud mit MariaDB
- Grundlegendes Kubernetes-VerstÃ¤ndnis
- Persistente Datenbank und Dateien

âœ… **Stufe 2 - Production-Ready:**
- HochverfÃ¼gbarkeit (3 Nextcloud-Replicas)
- StatefulSet fÃ¼r Datenbank
- Resource Management (Requests/Limits)
- Health Checks (Liveness/Readiness)
- Network Policies (Security)
- LoadBalancer Service (externer Zugriff)

âœ… **Stufe 3 - Enterprise:**
- HTTPS mit automatischen Zertifikaten
- Ingress mit Domain
- Prometheus Monitoring
- Grafana Dashboards
- Automatische Backups
- Integration mit HA-Cluster

### Produktionsreife Features

| Feature | Stufe 1 | Stufe 2 | Stufe 3 |
|---------|---------|---------|---------|
| FunktionalitÃ¤t | âœ… | âœ… | âœ… |
| HochverfÃ¼gbarkeit | âŒ | âœ… | âœ… |
| Resource Limits | âŒ | âœ… | âœ… |
| Health Checks | âŒ | âœ… | âœ… |
| Network Security | âŒ | âœ… | âœ… |
| Externer Zugriff | Port-Forward | LoadBalancer | Ingress + TLS |
| Monitoring | âŒ | âŒ | âœ… |
| Backups | âŒ | âŒ | âœ… |
| **Production-Ready** | âŒ | âš ï¸ | âœ… |

### NÃ¤chste Schritte

1. **Performance-Tuning:**
   - Redis fÃ¼r Caching
   - MariaDB Query-Optimierung
   - CDN fÃ¼r statische Assets

2. **Erweiterte Security:**
   - RBAC fÃ¼r Nextcloud ServiceAccount
   - Pod Security Policies
   - OPA/Gatekeeper fÃ¼r Policy Enforcement

3. **Skalierung:**
   - Horizontal Pod Autoscaler (HPA)
   - Vertical Pod Autoscaler (VPA)
   - Cluster Autoscaler

4. **Multi-Tenant:**
   - Mehrere Nextcloud-Instanzen pro Namespace
   - Shared MariaDB mit separaten Datenbanken

5. **Disaster Recovery:**
   - Velero fÃ¼r Cluster-weite Backups
   - Cross-Region Replikation
   - Chaos Engineering (Failure-Tests)

---

## AnhÃ¤nge

### A.1 VollstÃ¤ndige YAML-Manifeste

Alle Manifeste sind verfÃ¼gbar in:
- `Kubernetes HA/manifests/nextcloud/`

### A.2 Skript-Sammlung

- `deploy-nextcloud-basic.sh`: Stufe 1 automatisch deployen
- `deploy-nextcloud-production.sh`: Stufe 2+3 deployen
- `backup-nextcloud-full.sh`: VollstÃ¤ndiges Backup
- `restore-nextcloud.sh`: Disaster Recovery

### A.3 Troubleshooting-Matrix

| Problem | Symptom | Diagnose-Command | LÃ¶sung |
|---------|---------|------------------|--------|
| Pod startet nicht | CrashLoopBackOff | `kubectl logs` | Logs prÃ¼fen, Events checken |
| DB nicht erreichbar | Connection refused | `kubectl exec -- ping mariadb` | Service/NetworkPolicy prÃ¼fen |
| Datei-Upload fehl | 413 Payload Too Large | `kubectl describe ingress` | proxy-body-size erhÃ¶hen |
| Langsame Performance | Hohe Latenz | `kubectl top pods` | Mehr Replicas, Resources erhÃ¶hen |
| Zertifikat ungÃ¼ltig | HTTPS-Warnung | `kubectl describe certificate` | Cert-Manager Logs prÃ¼fen |

---

**Viel Erfolg mit Ihrer produktionsreifen Nextcloud-Installation auf Kubernetes!** ğŸš€

